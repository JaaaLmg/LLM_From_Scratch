# LLM From Scratch

希望尝试理解并动手编写一个小型的GPT（基于GPT2），并完成训练、微调等工作
如果一切看起来还不错，再学习和实现一些其他模型与算法

---

## 参考教程
- https://github.com/karpathy/build-nanogpt
- https://github.com/karpathy/nanoGPT
- https://github.com/karpathy/nanochat
- https://github.com/bbruceyuan/LLMs-Zero-to-Hero

## 目录结构
```
.
├── images
├── README.md
├── notebooks
│   ├── GPT.ipynb       # gpt2(124M)的简易实现
│   ├── loadGPT2.ipynb  # 加载官方的gpt2权重
|
```

## 待办
- [ ] GPT2的简易实现
- [ ] 数据收集与处理（中/英文）
- [ ] 预训练和测试
- [ ] SFT、偏好对齐
- [ ] 做一个UI
- [ ] 其他的模型和算法
